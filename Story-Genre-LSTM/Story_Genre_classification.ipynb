{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Story-Genre-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "14EjYHvekpQy3VY3VQ0mc81-w2wjYieTU",
      "authorship_tag": "ABX9TyP6D5l0/dr/+12JH9q9/18u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guramritpalsaggu/NLP/blob/master/Story_Genre_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ETVoS2rzuMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, SpatialDropout1D, GlobalAveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from scipy.sparse import hstack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt3g_zbAkOOS",
        "colab_type": "text"
      },
      "source": [
        "Loading the train and test files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnsgSpL73j1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/HackerearthSME/dataset/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/HackerearthSME/dataset/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM3Lms-y2Ipl",
        "colab_type": "code",
        "outputId": "8fe1d66c-47a5-4218-82f5-3b72875d17b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Release Year</th>\n",
              "      <th>Title</th>\n",
              "      <th>Language</th>\n",
              "      <th>Writer</th>\n",
              "      <th>No. of readers</th>\n",
              "      <th>Story</th>\n",
              "      <th>Genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MID_3037</td>\n",
              "      <td>2014</td>\n",
              "      <td>aiMudhrnalac A Vis</td>\n",
              "      <td>Tamil</td>\n",
              "      <td>Thiraivannan</td>\n",
              "      <td>1527</td>\n",
              "      <td>The title “Adra Machan Visilu” fellows blow a ...</td>\n",
              "      <td>type0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MID_4958</td>\n",
              "      <td>2005</td>\n",
              "      <td>Oamthm ni OS</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>Farah Khan</td>\n",
              "      <td>582</td>\n",
              "      <td>Om Prakash Makhija, a junior artist in 1970s H...</td>\n",
              "      <td>type1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MID_10092</td>\n",
              "      <td>2018</td>\n",
              "      <td>EtNehr ir</td>\n",
              "      <td>Tamil</td>\n",
              "      <td>M.Jaya Pradeep</td>\n",
              "      <td>15751</td>\n",
              "      <td>Karthik (Richard) gets a call from his friend ...</td>\n",
              "      <td>type3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MID_3723</td>\n",
              "      <td>1992</td>\n",
              "      <td>W'rHs annaa</td>\n",
              "      <td>English</td>\n",
              "      <td>Menahem Golan</td>\n",
              "      <td>2918</td>\n",
              "      <td>Hannah Senesh was a real-life Hungarian Jew wh...</td>\n",
              "      <td>type4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MID_9675</td>\n",
              "      <td>1986</td>\n",
              "      <td>haaasa lBasoBbhobal</td>\n",
              "      <td>Bengali</td>\n",
              "      <td>Tarun Majumdar</td>\n",
              "      <td>12071</td>\n",
              "      <td>Keya (Debashree Roy) is a college student who ...</td>\n",
              "      <td>type1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  ...  Genre\n",
              "0   MID_3037  ...  type0\n",
              "1   MID_4958  ...  type1\n",
              "2  MID_10092  ...  type3\n",
              "3   MID_3723  ...  type4\n",
              "4   MID_9675  ...  type1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOnfkswztsq",
        "colab_type": "text"
      },
      "source": [
        "**Exploratory Data Analysis and Data Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOTnypxGx2H_",
        "colab_type": "text"
      },
      "source": [
        "Their is no missing values in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRRONGXeA9B_",
        "colab_type": "code",
        "outputId": "6d695ceb-ac29-4fff-df79-742a9fee99cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "train.isnull().any(),test.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(ID                False\n",
              " Release Year      False\n",
              " Title             False\n",
              " Language          False\n",
              " Writer            False\n",
              " No. of readers    False\n",
              " Story             False\n",
              " Genre             False\n",
              " dtype: bool, ID                False\n",
              " Release Year      False\n",
              " Title             False\n",
              " Language          False\n",
              " Writer            False\n",
              " No. of readers    False\n",
              " Story             False\n",
              " dtype: bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaZEWmJbxn34",
        "colab_type": "text"
      },
      "source": [
        "Distribution is even of all the Genre's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QmYhUiWvSAv",
        "colab_type": "code",
        "outputId": "af57b826-2889-45a0-ea25-3d3b161b2c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "train['Genre'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type2    1102\n",
              "type4    1100\n",
              "type0    1094\n",
              "type1     909\n",
              "type3     845\n",
              "Name: Genre, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kOpaL1OyVeG",
        "colab_type": "text"
      },
      "source": [
        "Genre column need to be encoded and for that will use get_dummies function of pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iri0B6LWCGC5",
        "colab_type": "code",
        "outputId": "1bdbe062-1daa-45d8-8301-32d34d21ef8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "train = pd.get_dummies(train, columns=['Genre'])\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Release Year</th>\n",
              "      <th>Title</th>\n",
              "      <th>Language</th>\n",
              "      <th>Writer</th>\n",
              "      <th>No. of readers</th>\n",
              "      <th>Story</th>\n",
              "      <th>Genre_type0</th>\n",
              "      <th>Genre_type1</th>\n",
              "      <th>Genre_type2</th>\n",
              "      <th>Genre_type3</th>\n",
              "      <th>Genre_type4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MID_3037</td>\n",
              "      <td>2014</td>\n",
              "      <td>aiMudhrnalac A Vis</td>\n",
              "      <td>Tamil</td>\n",
              "      <td>Thiraivannan</td>\n",
              "      <td>1527</td>\n",
              "      <td>The title “Adra Machan Visilu” fellows blow a ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MID_4958</td>\n",
              "      <td>2005</td>\n",
              "      <td>Oamthm ni OS</td>\n",
              "      <td>Hindi</td>\n",
              "      <td>Farah Khan</td>\n",
              "      <td>582</td>\n",
              "      <td>Om Prakash Makhija, a junior artist in 1970s H...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MID_10092</td>\n",
              "      <td>2018</td>\n",
              "      <td>EtNehr ir</td>\n",
              "      <td>Tamil</td>\n",
              "      <td>M.Jaya Pradeep</td>\n",
              "      <td>15751</td>\n",
              "      <td>Karthik (Richard) gets a call from his friend ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MID_3723</td>\n",
              "      <td>1992</td>\n",
              "      <td>W'rHs annaa</td>\n",
              "      <td>English</td>\n",
              "      <td>Menahem Golan</td>\n",
              "      <td>2918</td>\n",
              "      <td>Hannah Senesh was a real-life Hungarian Jew wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MID_9675</td>\n",
              "      <td>1986</td>\n",
              "      <td>haaasa lBasoBbhobal</td>\n",
              "      <td>Bengali</td>\n",
              "      <td>Tarun Majumdar</td>\n",
              "      <td>12071</td>\n",
              "      <td>Keya (Debashree Roy) is a college student who ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          ID  Release Year  ... Genre_type3 Genre_type4\n",
              "0   MID_3037          2014  ...           0           0\n",
              "1   MID_4958          2005  ...           0           0\n",
              "2  MID_10092          2018  ...           1           0\n",
              "3   MID_3723          1992  ...           0           1\n",
              "4   MID_9675          1986  ...           0           0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0R_ZwLEz6_k",
        "colab_type": "text"
      },
      "source": [
        "Genre of the movie depend on the **Story** only as other parameters given here are not useful for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z4Zbx3tm7N6",
        "colab_type": "text"
      },
      "source": [
        "Split the dependant and independant variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Uzj1-1bA9Pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"Genre_type0\", \"Genre_type1\", \"Genre_type2\", \"Genre_type3\", \"Genre_type4\"]\n",
        "y_train = train[labels].values\n",
        "list_sentences_train = train[\"Story\"]\n",
        "list_sentences_test = test[\"Story\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUK1_welni5Q",
        "colab_type": "text"
      },
      "source": [
        "The approach that we are taking is to feed the \"Story\" into the LSTM(Long Short-Term Memory) as part of the neural network but we can't just feed the words as it is.\n",
        "\n",
        "So this is what we are going to do:\n",
        "\n",
        "1. Tokenization - We need to break down the sentence into unique words. For eg, \"I love cats and love dogs\" will become [\"I\",\"love\",\"cats\",\"and\",\"dogs\"]\n",
        "2. Indexing - We put the words in a dictionary-like structure and give them an index each For eg, {1:\"I\",2:\"love\",3:\"cats\",4:\"and\",5:\"dogs\"}\n",
        "3. Index Representation- We could represent the sequence of words in the comments in the form of index, and feed this chain of index into our LSTM. For eg, [1,2,3,4,2,5]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP6rZkJ1A9VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 70000        # Number of unique words in the dictionary when tokenizing the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fwizNgCNMQV",
        "colab_type": "text"
      },
      "source": [
        "Now, if we look at \"list_tokenized_train\", we will see that Keras has turned our words into index representation for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LKfolUgDZZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_tokenized_train[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3TpGGXFNcV6",
        "colab_type": "text"
      },
      "source": [
        "But there's still 1 problem! What if some Stories are terribly long, while some are short. Wouldn't our indexed-sentence look like this:\n",
        "\n",
        "Story #1: [8,9,3,7,3,6,3,6,3,6,2,3,4,9]\n",
        "\n",
        "Story #2: [1,2,5,6,7]\n",
        "\n",
        "And we have to feed a stream of data that has a consistent length(fixed number of features).\n",
        "\n",
        "And this is why we use \"padding\"! We could make the shorter sentences as long as the others by filling the shortfall by zeros.But on the other hand, we also have to trim the longer ones to the same length(maxlen) as the short ones.\n",
        "\n",
        "One of the ways to go about it is to see the distribution of the number of words in sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDX6zRAyA9if",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totalNumWords = [len(one_story) for one_story in list_tokenized_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTETFrB_A9qi",
        "colab_type": "code",
        "outputId": "5c7c2f2d-15ee-46e5-e000-cc92a3da9fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "plt.hist(totalNumWords, bins = np.arange(0, 1000, 10))\n",
        "plt.xlabel('No of words')\n",
        "plt.ylabel('No of Sentence/Story')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCR1mBQkSR0mBUlSh0lBktRhUpAkdfx/l9Y8T88B3dMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1Tae5PSLWL",
        "colab_type": "text"
      },
      "source": [
        "From the above plot we can see the distribution of number of words against stories and see that most of stories has length less than 150. We can also try out other values for maxlen but we need to keep in mind that length should not be too small as it will result in lose of some useful features and too long will make it difficult to store these values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2IMhorBRElB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 150\n",
        "X_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhFuvMbDVnLw",
        "colab_type": "text"
      },
      "source": [
        "**Build Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s92eNzGYTz6q",
        "colab_type": "text"
      },
      "source": [
        "Now as we are finished preprocessing the text, we will now proceed to build the model. Model which we have build here is Bidirectional LSTM with Convolution.Our model consists of an initial LSTM layer which will receive word embeddings. The intuition is that its output tokens will store information not only of the initial token, but also any previous tokens, the LSTM layer is generating a new encoding for the original input. The output of the LSTM layer is then fed into a convolution layer which we expect will extract local features. Finally the convolution layer’s output will be pooled to a smaller dimension and ultimately output with genre of the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBrqMiQdV_wB",
        "colab_type": "text"
      },
      "source": [
        "The inputs into our networks is our list of encoded sentences. We begin by \n",
        "defining an Input layer that accepts a list of sentences that has a dimension of 150."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_ZrMZjhxDH9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=16z0Y0YZ4uTwSM9cS6Ry6dD2Uwdc3H5qI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGQzjhwjq13z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_input = Input(shape=(maxlen, ))  #maxlen=150 as defined earlier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MuVwTfxs3ne",
        "colab_type": "text"
      },
      "source": [
        "Next, we pass it to our Embedding layer, where we project the words to a defined vector space depending on the distance of the surrounding words in a sentence. Embedding allows us to reduce model size and most importantly the huge dimensions we have to deal with, in the case of using one-hot encoding to represent the words in our sentence.\n",
        "\n",
        "The output of the Embedding layer is a list of the coordinates of the words in this vector space.\n",
        "\n",
        "We need to define the size of the \"vector space\" we have mentioned above, and the number of unique words(max_features) we are using. Again, the embedding size is a parameter that we can tune and experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAEgC6iaq10r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 300\n",
        "x = Embedding(max_features, embed_size)(sequence_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3VaSVOlvuoQ",
        "colab_type": "text"
      },
      "source": [
        "Imagine that the LSTM is split between 2 hidden states for each time step. As the sequence of words is being feed into the LSTM in a forward fashion, there's another reverse sequence that is feeding to the different hidden state at the same time. You might noticed later at the model summary that the output dimension of LSTM layer has doubled to 120 because 60 dimensions are used for forward, and another 60 are used for reverse.\n",
        "\n",
        "The greatest advantage in using Bidirectional LSTM is that when it runs backwards you preserve information from the future and using the two hidden states combined, you are able in any point in time to preserve information from both past and future.\n",
        "\n",
        "LSTM Dropout is a probabilistic drop out layer on the inputs in each time step.\n",
        "\n",
        "Recurrent drop out is something like a dropout mask that applies drop out between the hidden states throughout the recursion of the whole LSTM network.\n",
        "\n",
        "Output from the previous embedding layer which outputs a 3-D tensor of (None,150, 300) into the LSTM layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOfbKx3kyyFA",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1y-WY85tJLg3EJlWvS2dzdLsVTmd9x_aJ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C-Ys5Joq1ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Bidirectional(LSTM(60, return_sequences=True,name='lstm_layer',dropout=0.1,recurrent_dropout=0.1))(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzzrpSWGzMqr",
        "colab_type": "text"
      },
      "source": [
        "Before we could pass the output to a normal layer, we need to reshape the 3D tensor into a 2D one. We reshape carefully to avoid throwing away data that is important to us, and ideally we want the resulting data to be a good representative of the original data.\n",
        "\n",
        "Therefore, we use a Global Max Pooling layer which is used in CNN to reduce the dimensionality of image data. We go through each patch of data, and we take the maximum values of each patch. These collection of maximum values will be a new set of down-sized data we can use.\n",
        "\n",
        "Finally, we feed the output into a Sigmoid layer. The reason why sigmoid is used is because we are trying to achieve a binary classification(1,0) for each of the 5 labels, and the sigmoid function will keep the output between the bounds of 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEPTcXfrq1lP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(50, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(5, activation=\"sigmoid\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOdvhv7ZVFEn",
        "colab_type": "text"
      },
      "source": [
        "Model will optimize our loss function using Adam optimizer, define the loss function to be \"binary_crossentropy\" since we are dealing with a binary classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWSYtqeVA9uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=sequence_input, outputs=x)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(lr=1e-3),\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VEjDbXJv3hq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pP6DU5cVqSq",
        "colab_type": "text"
      },
      "source": [
        "Saving only the best model and using Early Stopping to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7zFbtqBhJ1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.9, random_state=233)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iEebwFg3wLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"weights_base.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=3)\n",
        "callbacks_list = [checkpoint, early]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVqA3LjJA9ya",
        "colab_type": "code",
        "outputId": "a3cba98b-a4e6-4c82-e994-0e49b9e3ba54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 5\n",
        "model.fit(X_train, y_train, \n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs, \n",
        "          validation_data = (X_val,y_val),\n",
        "          callbacks = callbacks_list,\n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4545 samples, validate on 505 samples\n",
            "Epoch 1/5\n",
            "4545/4545 [==============================] - 27s 6ms/step - loss: 0.0442 - acc: 0.9900 - val_loss: 0.4655 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.85743\n",
            "Epoch 2/5\n",
            "4545/4545 [==============================] - 28s 6ms/step - loss: 0.0197 - acc: 0.9963 - val_loss: 0.5125 - val_acc: 0.8515\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.85743\n",
            "Epoch 3/5\n",
            "4545/4545 [==============================] - 28s 6ms/step - loss: 0.0125 - acc: 0.9976 - val_loss: 0.5093 - val_acc: 0.8634\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.85743 to 0.86337, saving model to weights_base.best.hdf5\n",
            "Epoch 4/5\n",
            "4545/4545 [==============================] - 28s 6ms/step - loss: 0.0113 - acc: 0.9974 - val_loss: 0.5810 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.86337\n",
            "Epoch 5/5\n",
            "4545/4545 [==============================] - 27s 6ms/step - loss: 0.0085 - acc: 0.9984 - val_loss: 0.5812 - val_acc: 0.8539\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.86337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff450162588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1SGXlkFA9f0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mMQ8gRTA88-",
        "colab_type": "code",
        "outputId": "4f5118e4-2897-403a-9dfd-532f5b59f7d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.load_weights(filepath)\n",
        "print('Predicting....')\n",
        "y_pred = model.predict(X_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting....\n",
            "2361/2361 [==============================] - 18s 8ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOqJMl1nV33X",
        "colab_type": "text"
      },
      "source": [
        "We have achieved the validation accuracy of about 86% here. We have experimented with various parameters and the accuracy varies around 85+-2%.\n",
        "\n",
        "TODOs: We could use pretrained embedding such as Glove, Fasttext, Word2Vec etc and see if could improve our results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JZTdFxNa3ro",
        "colab_type": "text"
      },
      "source": [
        "Now we need to export our results into the submission.csv "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pufjjvi8zwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = pd.DataFrame(y_pred)\n",
        "y = y_pred.idxmax(axis = 1)\n",
        "dic = {0:\"type0\", 1:\"type1\", 2:\"type2\", 3:\"type3\", 4:\"type4\"}\n",
        "submission = pd.read_csv('/content/drive/My Drive/HackerearthSME/dataset/test.csv')\n",
        "submission = submission.drop([\"Release Year\",\"Title\",\"Language\",\"Writer\",\"No. of readers\",\"Story\"], axis=1)\n",
        "submission['Genre'] = y\n",
        "submission.Genre = submission.Genre.map(dic)\n",
        "submission.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scebs0hi8zzg",
        "colab_type": "code",
        "outputId": "02ce7a37-cc44-4208-f8d8-d4ea33cb72b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.71998143e-03, 4.46140766e-05, 3.85880470e-04, 9.97099876e-01,\n",
              "        8.87542963e-04],\n",
              "       [5.78790903e-04, 3.57627869e-07, 1.15783125e-01, 3.41236591e-05,\n",
              "        9.82372046e-01],\n",
              "       [9.42593455e-01, 1.44541264e-04, 2.60680914e-04, 1.72734261e-04,\n",
              "        1.36012316e-01],\n",
              "       ...,\n",
              "       [4.48822975e-05, 8.10325146e-05, 5.94251037e-01, 4.94436294e-01,\n",
              "        2.97397375e-04],\n",
              "       [3.89816463e-02, 2.11596489e-06, 5.12003899e-05, 1.87414974e-01,\n",
              "        1.46663189e-01],\n",
              "       [9.68728840e-01, 6.61662221e-03, 9.43094492e-04, 3.66657972e-04,\n",
              "        4.18593921e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAPt7Z_7loyB",
        "colab_type": "text"
      },
      "source": [
        "Apart from LSTM Network, we have tried Logistic Regression, Naive Bayes but the cross validation score was around 80-82% with TF-IDF vectorization for words and characters\n",
        "\n",
        "TODOS: We can tune the hyperparameter's using randomized grid search and improve our results.\n",
        "Some more text classification methods and text preprocessing can be tried on to improve the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM2FgRGNyk_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['Genre_type0','Genre_type1','Genre_type2','Genre_type3','Genre_type4']\n",
        "train_text = train['Story']\n",
        "test_text = test['Story']\n",
        "all_text = pd.concat([train_text, test_text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVhRxgz2yk2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 1),\n",
        "    max_features=10000)\n",
        "word_vectorizer.fit(all_text)\n",
        "train_word_features = word_vectorizer.transform(train_text)\n",
        "test_word_features = word_vectorizer.transform(test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUUEOei8ykpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    stop_words='english',\n",
        "    ngram_range=(2, 6),\n",
        "    max_features=50000)\n",
        "char_vectorizer.fit(all_text)\n",
        "train_char_features = char_vectorizer.transform(train_text)\n",
        "test_char_features = char_vectorizer.transform(test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2mYM2hQysSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = hstack([train_char_features, train_word_features])\n",
        "test_features = hstack([test_char_features, test_word_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nnqkCuJi5qX",
        "colab_type": "code",
        "outputId": "349c1c98-c08a-4ca7-c785-1cc8e0dfff66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "scores = []\n",
        "submission = pd.DataFrame.from_dict({'ID': test['ID']})\n",
        "for class_name in class_names:\n",
        "    train_target = train[class_name]\n",
        "    classifier = LogisticRegression(C=0.1, solver='sag')\n",
        "\n",
        "    cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='accuracy'))\n",
        "    scores.append(cv_score)\n",
        "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
        "\n",
        "    classifier.fit(train_features, train_target)\n",
        "    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
        "\n",
        "print('Total CV score is {}'.format(np.mean(scores)))\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CV score for class Genre_type0 is 0.7833663588518975\n",
            "CV score for class Genre_type1 is 0.8199999858865304\n",
            "CV score for class Genre_type2 is 0.7817822395159268\n",
            "CV score for class Genre_type3 is 0.8326732934110327\n",
            "CV score for class Genre_type4 is 0.7835643002612404\n",
            "Total CV score is 0.8002772355853255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsO1ZaEp6gy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_score(model, train_text, y_train, cv=3, scoring = None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iEbfdCVyHzP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}